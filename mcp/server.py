# mcp/server.py
"""
Enhanced MCP Server with AI Memory Processing for aigpt CLI
"""
import json
import os
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn
import asyncio
import aiohttp

# ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
class ChatMessage(BaseModel):
    message: str
    model: Optional[str] = None

class MemoryQuery(BaseModel):
    query: str
    limit: Optional[int] = 10

class ConversationImport(BaseModel):
    conversation_data: Dict[str, Any]

class MemorySummaryRequest(BaseModel):
    filepath: str
    ai_provider: Optional[str] = "openai"

class RelationshipUpdate(BaseModel):
    target: str  # å¯¾è±¡è€…/ãƒˆãƒ”ãƒƒã‚¯
    interaction_type: str  # "positive", "negative", "neutral"
    weight: float = 1.0
    context: Optional[str] = None

# è¨­å®š
BASE_DIR = Path.home() / ".config" / "aigpt"
MEMORY_DIR = BASE_DIR / "memory"
CHATGPT_MEMORY_DIR = MEMORY_DIR / "chatgpt"
PROCESSED_MEMORY_DIR = MEMORY_DIR / "processed"
RELATIONSHIP_DIR = BASE_DIR / "relationships"

def init_directories():
    """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    BASE_DIR.mkdir(parents=True, exist_ok=True)
    MEMORY_DIR.mkdir(parents=True, exist_ok=True)
    CHATGPT_MEMORY_DIR.mkdir(parents=True, exist_ok=True)
    PROCESSED_MEMORY_DIR.mkdir(parents=True, exist_ok=True)
    RELATIONSHIP_DIR.mkdir(parents=True, exist_ok=True)

class AIMemoryProcessor:
    """AIè¨˜æ†¶å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        # AI APIã®è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.anthropic_api_key = os.getenv("ANTHROPIC_API_KEY")
    
    async def generate_ai_summary(self, messages: List[Dict[str, Any]], provider: str = "openai") -> Dict[str, Any]:
        """AIã‚’ä½¿ç”¨ã—ã¦ä¼šè©±ã®é«˜åº¦ãªè¦ç´„ã¨åˆ†æã‚’ç”Ÿæˆ"""
        
        # ä¼šè©±å†…å®¹ã‚’çµåˆ
        conversation_text = ""
        for msg in messages[-20:]:  # æœ€æ–°20ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨
            role = "User" if msg["role"] == "user" else "Assistant"
            conversation_text += f"{role}: {msg['content'][:500]}\n"
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        analysis_prompt = f"""
ä»¥ä¸‹ã®ä¼šè©±ã‚’åˆ†æã—ã€JSONå½¢å¼ã§ä»¥ä¸‹ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š

1. main_topics: ä¸»ãªãƒˆãƒ”ãƒƒã‚¯ï¼ˆæœ€å¤§5å€‹ï¼‰
2. user_intent: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚„ç›®çš„
3. key_insights: é‡è¦ãªæ´å¯Ÿã‚„å­¦ã³ï¼ˆæœ€å¤§3å€‹ï¼‰
4. relationship_indicators: é–¢ä¿‚æ€§ã‚’ç¤ºã™è¦ç´ 
5. emotional_tone: æ„Ÿæƒ…çš„ãªãƒˆãƒ¼ãƒ³
6. action_items: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚„æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
7. summary: 100æ–‡å­—ä»¥å†…ã®è¦ç´„

ä¼šè©±å†…å®¹:
{conversation_text}

å›ç­”ã¯JSONå½¢å¼ã®ã¿ã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
        
        try:
            if provider == "openai" and self.openai_api_key:
                return await self._call_openai_api(analysis_prompt)
            elif provider == "anthropic" and self.anthropic_api_key:
                return await self._call_anthropic_api(analysis_prompt)
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬çš„ãªåˆ†æ
                return self._generate_basic_analysis(messages)
        except Exception as e:
            print(f"AI analysis failed: {e}")
            return self._generate_basic_analysis(messages)
    
    async def _call_openai_api(self, prompt: str) -> Dict[str, Any]:
        """OpenAI APIã‚’å‘¼ã³å‡ºã—"""
        async with aiohttp.ClientSession() as session:
            headers = {
                "Authorization": f"Bearer {self.openai_api_key}",
                "Content-Type": "application/json"
            }
            data = {
                "model": "gpt-4",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 1000
            }
            
            async with session.post("https://api.openai.com/v1/chat/completions", 
                                  headers=headers, json=data) as response:
                result = await response.json()
                content = result["choices"][0]["message"]["content"]
                return json.loads(content)
    
    async def _call_anthropic_api(self, prompt: str) -> Dict[str, Any]:
        """Anthropic APIã‚’å‘¼ã³å‡ºã—"""
        async with aiohttp.ClientSession() as session:
            headers = {
                "x-api-key": self.anthropic_api_key,
                "Content-Type": "application/json",
                "anthropic-version": "2023-06-01"
            }
            data = {
                "model": "claude-3-sonnet-20240229",
                "max_tokens": 1000,
                "messages": [{"role": "user", "content": prompt}]
            }
            
            async with session.post("https://api.anthropic.com/v1/messages",
                                  headers=headers, json=data) as response:
                result = await response.json()
                content = result["content"][0]["text"]
                return json.loads(content)
    
    def _generate_basic_analysis(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åŸºæœ¬çš„ãªåˆ†æï¼ˆAI APIãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        user_messages = [msg for msg in messages if msg["role"] == "user"]
        assistant_messages = [msg for msg in messages if msg["role"] == "assistant"]
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
        all_text = " ".join([msg["content"] for msg in messages])
        words = all_text.lower().split()
        word_freq = {}
        for word in words:
            if len(word) > 3:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return {
            "main_topics": [word[0] for word in top_words],
            "user_intent": "æƒ…å ±åé›†ãƒ»å•é¡Œè§£æ±º",
            "key_insights": ["åŸºæœ¬çš„ãªä¼šè©±åˆ†æ"],
            "relationship_indicators": {
                "interaction_count": len(messages),
                "user_engagement": len(user_messages),
                "assistant_helpfulness": len(assistant_messages)
            },
            "emotional_tone": "neutral",
            "action_items": [],
            "summary": f"{len(user_messages)}å›ã®ã‚„ã‚Šå–ã‚Šã«ã‚ˆã‚‹ä¼šè©±"
        }

class RelationshipTracker:
    """é–¢ä¿‚æ€§è¿½è·¡ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        init_directories()
        self.relationship_file = RELATIONSHIP_DIR / "relationships.json"
        self.relationships = self._load_relationships()
    
    def _load_relationships(self) -> Dict[str, Any]:
        """é–¢ä¿‚æ€§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        if self.relationship_file.exists():
            with open(self.relationship_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"targets": {}, "last_updated": datetime.now().isoformat()}
    
    def _save_relationships(self):
        """é–¢ä¿‚æ€§ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        self.relationships["last_updated"] = datetime.now().isoformat()
        with open(self.relationship_file, 'w', encoding='utf-8') as f:
            json.dump(self.relationships, f, ensure_ascii=False, indent=2)
    
    def update_relationship(self, target: str, interaction_type: str, weight: float = 1.0, context: str = None):
        """é–¢ä¿‚æ€§ã‚’æ›´æ–°"""
        if target not in self.relationships["targets"]:
            self.relationships["targets"][target] = {
                "score": 0.0,
                "interactions": [],
                "created_at": datetime.now().isoformat(),
                "last_interaction": None
            }
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        score_change = 0.0
        if interaction_type == "positive":
            score_change = weight * 1.0
        elif interaction_type == "negative":
            score_change = weight * -1.0
        
        # æ™‚é–“æ¸›è¡°ã‚’é©ç”¨
        self._apply_time_decay(target)
        
        # ã‚¹ã‚³ã‚¢æ›´æ–°
        current_score = self.relationships["targets"][target]["score"]
        new_score = current_score + score_change
        
        # ã‚¹ã‚³ã‚¢ã®ç¯„å›²åˆ¶é™ï¼ˆ-100 to 100ï¼‰
        new_score = max(-100, min(100, new_score))
        
        self.relationships["targets"][target]["score"] = new_score
        self.relationships["targets"][target]["last_interaction"] = datetime.now().isoformat()
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å±¥æ­´ã‚’è¿½åŠ 
        interaction_record = {
            "type": interaction_type,
            "weight": weight,
            "score_change": score_change,
            "new_score": new_score,
            "timestamp": datetime.now().isoformat(),
            "context": context
        }
        
        self.relationships["targets"][target]["interactions"].append(interaction_record)
        
        # å±¥æ­´ã¯æœ€æ–°100ä»¶ã¾ã§ä¿æŒ
        if len(self.relationships["targets"][target]["interactions"]) > 100:
            self.relationships["targets"][target]["interactions"] = \
                self.relationships["targets"][target]["interactions"][-100:]
        
        self._save_relationships()
        return new_score
    
    def _apply_time_decay(self, target: str):
        """æ™‚é–“æ¸›è¡°ã‚’é©ç”¨"""
        target_data = self.relationships["targets"][target]
        last_interaction = target_data.get("last_interaction")
        
        if last_interaction:
            last_time = datetime.fromisoformat(last_interaction)
            now = datetime.now()
            days_passed = (now - last_time).days
            
            # 7æ—¥ã”ã¨ã«5%æ¸›è¡°
            if days_passed > 0:
                decay_factor = 0.95 ** (days_passed / 7)
                target_data["score"] *= decay_factor
    
    def get_relationship_score(self, target: str) -> float:
        """é–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢ã‚’å–å¾—"""
        if target in self.relationships["targets"]:
            self._apply_time_decay(target)
            return self.relationships["targets"][target]["score"]
        return 0.0
    
    def should_send_message(self, target: str, threshold: float = 50.0) -> bool:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã®å¯å¦ã‚’åˆ¤å®š"""
        score = self.get_relationship_score(target)
        return score >= threshold
    
    def get_all_relationships(self) -> Dict[str, Any]:
        """ã™ã¹ã¦ã®é–¢ä¿‚æ€§ã‚’å–å¾—"""
        # å…¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«æ™‚é–“æ¸›è¡°ã‚’é©ç”¨
        for target in self.relationships["targets"]:
            self._apply_time_decay(target)
        
        return self.relationships

class MemoryManager:
    """è¨˜æ†¶ç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆAIå‡¦ç†æ©Ÿèƒ½ä»˜ãï¼‰"""
    
    def __init__(self):
        init_directories()
        self.ai_processor = AIMemoryProcessor()
        self.relationship_tracker = RelationshipTracker()
    
    def parse_chatgpt_conversation(self, conversation_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ChatGPTã®ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º"""
        messages = []
        mapping = conversation_data.get("mapping", {})
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ™‚ç³»åˆ—é †ã«ä¸¦ã¹ã‚‹
        message_nodes = []
        for node_id, node in mapping.items():
            message = node.get("message")
            if not message:
                continue
            content = message.get("content", {})
            parts = content.get("parts", [])

            if parts and isinstance(parts[0], str) and parts[0].strip():
                message_nodes.append({
                    "id": node_id,
                    "create_time": message.get("create_time", 0),
                    "author_role": message["author"]["role"],
                    "content": parts[0],
                    "parent": node.get("parent")
                })
        
        # ä½œæˆæ™‚é–“ã§ã‚½ãƒ¼ãƒˆ
        message_nodes.sort(key=lambda x: x["create_time"] or 0)
        
        for msg in message_nodes:
            if msg["author_role"] in ["user", "assistant"]:
                messages.append({
                    "role": msg["author_role"],
                    "content": msg["content"],
                    "timestamp": msg["create_time"],
                    "message_id": msg["id"]
                })
        
        return messages
    
    async def save_chatgpt_memory(self, conversation_data: Dict[str, Any], process_with_ai: bool = True) -> str:
        """ChatGPTã®ä¼šè©±ã‚’è¨˜æ†¶ã¨ã—ã¦ä¿å­˜ï¼ˆAIå‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãï¼‰"""
        title = conversation_data.get("title", "untitled")
        create_time = conversation_data.get("create_time", datetime.now().timestamp())
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è§£æ
        messages = self.parse_chatgpt_conversation(conversation_data)
        
        if not messages:
            raise ValueError("No valid messages found in conversation")
        
        # AIåˆ†æã‚’å®Ÿè¡Œ
        ai_analysis = None
        if process_with_ai:
            try:
                ai_analysis = await self.ai_processor.generate_ai_summary(messages)
            except Exception as e:
                print(f"AI analysis failed: {e}")
        
        # åŸºæœ¬è¦ç´„ã‚’ç”Ÿæˆ
        basic_summary = self.generate_basic_summary(messages)
        
        # ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        memory_data = {
            "title": title,
            "source": "chatgpt",
            "import_time": datetime.now().isoformat(),
            "original_create_time": create_time,
            "messages": messages,
            "basic_summary": basic_summary,
            "ai_analysis": ai_analysis,
            "message_count": len(messages),
            "hash": self._generate_content_hash(messages)
        }
        
        # é–¢ä¿‚æ€§ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        if ai_analysis and "relationship_indicators" in ai_analysis:
            interaction_count = ai_analysis["relationship_indicators"].get("interaction_count", 0)
            if interaction_count > 10:  # é•·ã„ä¼šè©±ã¯é–¢ä¿‚æ€§ã«ãƒ—ãƒ©ã‚¹
                self.relationship_tracker.update_relationship(
                    target="user_general",
                    interaction_type="positive",
                    weight=min(interaction_count / 10, 5.0),
                    context=f"Long conversation: {title}"
                )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).rstrip()
        timestamp = datetime.fromtimestamp(create_time).strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{safe_title[:50]}.json"
        
        filepath = CHATGPT_MEMORY_DIR / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(memory_data, f, ensure_ascii=False, indent=2)
        
        # å‡¦ç†æ¸ˆã¿ãƒ¡ãƒ¢ãƒªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚‚ä¿å­˜
        if ai_analysis:
            processed_filepath = PROCESSED_MEMORY_DIR / filename
            with open(processed_filepath, 'w', encoding='utf-8') as f:
                json.dump(memory_data, f, ensure_ascii=False, indent=2)
        
        return str(filepath)
    
    def generate_basic_summary(self, messages: List[Dict[str, Any]]) -> str:
        """åŸºæœ¬è¦ç´„ã‚’ç”Ÿæˆ"""
        if not messages:
            return "Empty conversation"
        
        user_messages = [msg for msg in messages if msg["role"] == "user"]
        assistant_messages = [msg for msg in messages if msg["role"] == "assistant"]
        
        summary = f"Conversation with {len(user_messages)} user messages and {len(assistant_messages)} assistant responses. "
        
        if user_messages:
            first_user_msg = user_messages[0]["content"][:100]
            summary += f"Started with: {first_user_msg}..."
        
        return summary
    
    def _generate_content_hash(self, messages: List[Dict[str, Any]]) -> str:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã®ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ"""
        content = "".join([msg["content"] for msg in messages])
        return hashlib.sha256(content.encode()).hexdigest()[:16]
    
    def search_memories(self, query: str, limit: int = 10, use_ai_analysis: bool = True) -> List[Dict[str, Any]]:
        """è¨˜æ†¶ã‚’æ¤œç´¢ï¼ˆAIåˆ†æçµæœã‚‚å«ã‚€ï¼‰"""
        results = []
        
        # å‡¦ç†æ¸ˆã¿ãƒ¡ãƒ¢ãƒªã‹ã‚‰æ¤œç´¢
        search_dirs = [PROCESSED_MEMORY_DIR, CHATGPT_MEMORY_DIR] if use_ai_analysis else [CHATGPT_MEMORY_DIR]
        
        for search_dir in search_dirs:
            for filepath in search_dir.glob("*.json"):
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        memory_data = json.load(f)
                    
                    # æ¤œç´¢å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
                    search_text = f"{memory_data.get('title', '')} {memory_data.get('basic_summary', '')}"
                    
                    # AIåˆ†æçµæœã‚‚æ¤œç´¢å¯¾è±¡ã«å«ã‚ã‚‹
                    if memory_data.get('ai_analysis'):
                        ai_analysis = memory_data['ai_analysis']
                        search_text += f" {' '.join(ai_analysis.get('main_topics', []))}"
                        search_text += f" {ai_analysis.get('summary', '')}"
                        search_text += f" {' '.join(ai_analysis.get('key_insights', []))}"
                    
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‚‚æ¤œç´¢å¯¾è±¡ã«å«ã‚ã‚‹
                    for msg in memory_data.get('messages', []):
                        search_text += f" {msg.get('content', '')}"
                    
                    if query.lower() in search_text.lower():
                        result = {
                            "filepath": str(filepath),
                            "title": memory_data.get("title"),
                            "basic_summary": memory_data.get("basic_summary"),
                            "source": memory_data.get("source"),
                            "import_time": memory_data.get("import_time"),
                            "message_count": len(memory_data.get("messages", [])),
                            "has_ai_analysis": bool(memory_data.get("ai_analysis"))
                        }
                        
                        if memory_data.get('ai_analysis'):
                            result["ai_summary"] = memory_data['ai_analysis'].get('summary', '')
                            result["main_topics"] = memory_data['ai_analysis'].get('main_topics', [])
                        
                        results.append(result)
                        
                        if len(results) >= limit:
                            break
                            
                except Exception as e:
                    print(f"Error reading memory file {filepath}: {e}")
                    continue
            
            if len(results) >= limit:
                break
        
        return results
    
    def get_memory_detail(self, filepath: str) -> Dict[str, Any]:
        """è¨˜æ†¶ã®è©³ç´°ã‚’å–å¾—"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            raise ValueError(f"Error reading memory file: {e}")
    
    def list_all_memories(self) -> List[Dict[str, Any]]:
        """ã™ã¹ã¦ã®è¨˜æ†¶ã‚’ãƒªã‚¹ãƒˆ"""
        memories = []
        
        for filepath in CHATGPT_MEMORY_DIR.glob("*.json"):
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    memory_data = json.load(f)
                
                memory_info = {
                    "filepath": str(filepath),
                    "title": memory_data.get("title"),
                    "basic_summary": memory_data.get("basic_summary"),
                    "source": memory_data.get("source"),
                    "import_time": memory_data.get("import_time"),
                    "message_count": len(memory_data.get("messages", [])),
                    "has_ai_analysis": bool(memory_data.get("ai_analysis"))
                }
                
                if memory_data.get('ai_analysis'):
                    memory_info["ai_summary"] = memory_data['ai_analysis'].get('summary', '')
                    memory_info["main_topics"] = memory_data['ai_analysis'].get('main_topics', [])
                
                memories.append(memory_info)
            except Exception as e:
                print(f"Error reading memory file {filepath}: {e}")
                continue
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚é–“ã§ã‚½ãƒ¼ãƒˆ
        memories.sort(key=lambda x: x.get("import_time", ""), reverse=True)
        return memories

# FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
app = FastAPI(title="AigptMCP Server with AI Memory", version="2.0.0")
memory_manager = MemoryManager()

@app.post("/memory/import/chatgpt")
async def import_chatgpt_conversation(data: ConversationImport, process_with_ai: bool = True):
    """ChatGPTã®ä¼šè©±ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆAIå‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãï¼‰"""
    try:
        filepath = await memory_manager.save_chatgpt_memory(data.conversation_data, process_with_ai)
        return {
            "success": True,
            "message": "Conversation imported successfully",
            "filepath": filepath,
            "ai_processed": process_with_ai
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/memory/process-ai")
async def process_memory_with_ai(data: MemorySummaryRequest):
    """æ—¢å­˜ã®è¨˜æ†¶ã‚’AIã§å†å‡¦ç†"""
    try:
        # æ—¢å­˜è¨˜æ†¶ã‚’èª­ã¿è¾¼ã¿
        memory_data = memory_manager.get_memory_detail(data.filepath)
        
        # AIåˆ†æã‚’å®Ÿè¡Œ
        ai_analysis = await memory_manager.ai_processor.generate_ai_summary(
            memory_data["messages"], 
            data.ai_provider
        )
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        memory_data["ai_analysis"] = ai_analysis
        memory_data["ai_processed_at"] = datetime.now().isoformat()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
        with open(data.filepath, 'w', encoding='utf-8') as f:
            json.dump(memory_data, f, ensure_ascii=False, indent=2)
        
        # å‡¦ç†æ¸ˆã¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚‚ã‚³ãƒ”ãƒ¼
        processed_filepath = PROCESSED_MEMORY_DIR / Path(data.filepath).name
        with open(processed_filepath, 'w', encoding='utf-8') as f:
            json.dump(memory_data, f, ensure_ascii=False, indent=2)
        
        return {
            "success": True,
            "message": "Memory processed with AI successfully",
            "ai_analysis": ai_analysis
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/memory/search")
async def search_memories(query: MemoryQuery):
    """è¨˜æ†¶ã‚’æ¤œç´¢"""
    try:
        results = memory_manager.search_memories(query.query, query.limit)
        return {
            "success": True,
            "results": results,
            "count": len(results)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/memory/list")
async def list_memories():
    """ã™ã¹ã¦ã®è¨˜æ†¶ã‚’ãƒªã‚¹ãƒˆ"""
    try:
        memories = memory_manager.list_all_memories()
        return {
            "success": True,
            "memories": memories,
            "count": len(memories)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/memory/detail")
async def get_memory_detail(filepath: str):
    """è¨˜æ†¶ã®è©³ç´°ã‚’å–å¾—"""
    try:
        detail = memory_manager.get_memory_detail(filepath)
        return {
            "success": True,
            "memory": detail
        }
    except Exception as e:
        raise HTTPException(status_code=404, detail=str(e))

@app.post("/relationship/update")
async def update_relationship(data: RelationshipUpdate):
    """é–¢ä¿‚æ€§ã‚’æ›´æ–°"""
    try:
        new_score = memory_manager.relationship_tracker.update_relationship(
            data.target, data.interaction_type, data.weight, data.context
        )
        return {
            "success": True,
            "new_score": new_score,
            "can_send_message": memory_manager.relationship_tracker.should_send_message(data.target)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/relationship/list")
async def list_relationships():
    """ã™ã¹ã¦ã®é–¢ä¿‚æ€§ã‚’ãƒªã‚¹ãƒˆ"""
    try:
        relationships = memory_manager.relationship_tracker.get_all_relationships()
        return {
            "success": True,
            "relationships": relationships
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/relationship/check")
async def check_send_permission(target: str, threshold: float = 50.0):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡å¯å¦ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        score = memory_manager.relationship_tracker.get_relationship_score(target)
        can_send = memory_manager.relationship_tracker.should_send_message(target, threshold)
        return {
            "success": True,
            "target": target,
            "score": score,
            "can_send_message": can_send,
            "threshold": threshold
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/chat")
async def chat_endpoint(data: ChatMessage):
    """ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ï¼ˆè¨˜æ†¶ã¨é–¢ä¿‚æ€§ã‚’æ´»ç”¨ï¼‰"""
    try:
        # é–¢é€£ã™ã‚‹è¨˜æ†¶ã‚’æ¤œç´¢
        memories = memory_manager.search_memories(data.message, limit=3)
        
        # ãƒ¡ãƒ¢ãƒªã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        memory_context = ""
        if memories:
            memory_context = "\n# Related memories:\n"
            for memory in memories:
                memory_context += f"- {memory['title']}: {memory.get('ai_summary', memory.get('basic_summary', ''))}\n"
                if memory.get('main_topics'):
                    memory_context += f"  Topics: {', '.join(memory['main_topics'])}\n"
        
        # é–¢ä¿‚æ€§æƒ…å ±ã‚’å–å¾—
        relationships = memory_manager.relationship_tracker.get_all_relationships()
        
        # å®Ÿéš›ã®ãƒãƒ£ãƒƒãƒˆå‡¦ç†
        enhanced_message = data.message
        if memory_context:
            enhanced_message = f"{data.message}\n\n{memory_context}"
        
        return {
            "success": True,
            "response": f"Enhanced response with memory context: {enhanced_message}",
            "memories_used": len(memories),
            "relationship_info": {
                "active_relationships": len(relationships.get("targets", {})),
                "can_initiate_conversations": sum(1 for target, data in relationships.get("targets", {}).items() 
                                                if memory_manager.relationship_tracker.should_send_message(target))
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
async def root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "service": "AigptMCP Server with AI Memory",
        "version": "2.0.0",
        "status": "running",
        "memory_dir": str(MEMORY_DIR),
        "features": [
            "AI-powered memory analysis",
            "Relationship tracking",
            "Advanced memory search",
            "Conversation import",
            "Auto-summary generation"
        ],
        "endpoints": [
            "/memory/import/chatgpt",
            "/memory/process-ai",
            "/memory/search",
            "/memory/list",
            "/memory/detail",
            "/relationship/update",
            "/relationship/list",
            "/relationship/check",
            "/chat"
        ]
    }

if __name__ == "__main__":
    print("ğŸš€ AigptMCP Server with AI Memory starting...")
    print(f"ğŸ“ Memory directory: {MEMORY_DIR}")
    print(f"ğŸ§  AI Memory processing: {'âœ… Enabled' if os.getenv('OPENAI_API_KEY') or os.getenv('ANTHROPIC_API_KEY') else 'âŒ Disabled (no API keys)'}")
    uvicorn.run(app, host="127.0.0.1", port=5000)
