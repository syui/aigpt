## scripts/ask.py
import sys
import json
import requests
from config import load_config
from datetime import datetime, timezone

def build_payload_openai(cfg, message: str):
    return {
        "model": cfg["model"],
        "tools": [
            {
                "type": "function",
                "function": {
                    "name": "ask_message",
                    "description": "éå»ã®è¨˜æ†¶ã‚’æ¤œç´¢ã—ã¾ã™",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "æ¤œç´¢ã—ãŸã„èªå¥"
                            }
                        },
                        "required": ["query"]
                    }
                }
            }
        ],
        "tool_choice": "auto",
        "messages": [
            {"role": "system", "content": "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„AIã§ã€å¿…è¦ã«å¿œã˜ã¦è¨˜æ†¶ã‹ã‚‰æƒ…å ±ã‚’æ¤œç´¢ã—ã¦å¿œç­”ã—ã¾ã™ã€‚"},
            {"role": "user", "content": message}
        ]
    }

def build_payload_mcp(message: str):
    return {
        "tool": "ask_message",  # MCPã‚µãƒ¼ãƒãƒ¼å´ã§å®šç¾©ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«å
        "input": {
            "message": message
        }
    }

def build_payload_openai(cfg, message: str):
    return {
        "model": cfg["model"],
        "messages": [
            {"role": "system", "content": "ã‚ãªãŸã¯æ€ã„ã‚„ã‚Šã®ã‚ã‚‹AIã§ã™ã€‚"},
            {"role": "user", "content": message}
        ],
        "temperature": 0.7
    }

def call_mcp(cfg, message: str):
    payload = build_payload_mcp(message)
    headers = {"Content-Type": "application/json"}
    response = requests.post(cfg["url"], headers=headers, json=payload)
    response.raise_for_status()
    return response.json().get("output", {}).get("response", "â“ å¿œç­”ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

def call_openai(cfg, message: str):
    # ãƒ„ãƒ¼ãƒ«å®šç¾©
    tools = [
        {
            "type": "function",
            "function": {
                "name": "memory",
                "description": "è¨˜æ†¶ã‚’æ¤œç´¢ã™ã‚‹",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æ¤œç´¢ã™ã‚‹èªå¥"
                        }
                    },
                    "required": ["query"]
                }
            }
        }
    ]

    # æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
    payload = {
        "model": cfg["model"],
        "messages": [
            {"role": "system", "content": "ã‚ãªãŸã¯AIã§ã€å¿…è¦ã«å¿œã˜ã¦ãƒ„ãƒ¼ãƒ«memoryã‚’ä½¿ã£ã¦è¨˜æ†¶ã‚’æ¤œç´¢ã—ã¾ã™ã€‚"},
            {"role": "user", "content": message}
        ],
        "tools": tools,
        "tool_choice": "auto"
    }

    headers = {
        "Authorization": f"Bearer {cfg['api_key']}",
        "Content-Type": "application/json",
    }

    res1 = requests.post(cfg["url"], headers=headers, json=payload)
    res1.raise_for_status()
    result = res1.json()

    # ğŸ§  tool_call ã•ã‚ŒãŸã‹ç¢ºèª
    if "tool_calls" in result["choices"][0]["message"]:
        tool_call = result["choices"][0]["message"]["tool_calls"][0]
        if tool_call["function"]["name"] == "memory":
            args = json.loads(tool_call["function"]["arguments"])
            query = args.get("query", "")
            print(f"ğŸ› ï¸ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ: memory(query='{query}')")

            # MCPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«POST
            memory_res = requests.post("http://127.0.0.1:5000/memory/search", json={"query": query})
            memory_json = memory_res.json()
            tool_output = memory_json.get("result", "ãªã—")

            # tool_outputã‚’AIã«è¿”ã™
            followup = {
                "model": cfg["model"],
                "messages": [
                    {"role": "system", "content": "ã‚ãªãŸã¯AIã§ã€å¿…è¦ã«å¿œã˜ã¦ãƒ„ãƒ¼ãƒ«memoryã‚’ä½¿ã£ã¦è¨˜æ†¶ã‚’æ¤œç´¢ã—ã¾ã™ã€‚"},
                    {"role": "user", "content": message},
                    {"role": "assistant", "tool_calls": result["choices"][0]["message"]["tool_calls"]},
                    {"role": "tool", "tool_call_id": tool_call["id"], "name": "memory", "content": tool_output}
                ]
            }

            res2 = requests.post(cfg["url"], headers=headers, json=followup)
            res2.raise_for_status()
            final_response = res2.json()
            return final_response["choices"][0]["message"]["content"]
            #print(tool_output)
            #print(cfg["model"])
            #print(final_response)

    # ãƒ„ãƒ¼ãƒ«æœªä½¿ç”¨ or é€šå¸¸å¿œç­”
    return result["choices"][0]["message"]["content"]

def call_ollama(cfg, message: str):
    payload = {
            "model": cfg["model"],
            "prompt": message,  # `prompt` â†’ `message` ã«ã™ã¹ãï¼ˆå¤‰æ•°æœªå®šç¾©ã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
            "stream": False
            }
    headers = {"Content-Type": "application/json"}
    response = requests.post(cfg["url"], headers=headers, json=payload)
    response.raise_for_status()
    return response.json().get("response", "âŒ å¿œç­”ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
def main():
    if len(sys.argv) < 2:
        print("Usage: ask.py 'your message'")
        return

    message = sys.argv[1]
    cfg = load_config()

    print(f"ğŸ” ä½¿ç”¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {cfg['provider']}")

    try:
        if cfg["provider"] == "openai":
            response = call_openai(cfg, message)
        elif cfg["provider"] == "mcp":
            response = call_mcp(cfg, message)
        elif cfg["provider"] == "ollama":
            response = call_ollama(cfg, message)
        else:
            raise ValueError(f"æœªå¯¾å¿œã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {cfg['provider']}")

        print("ğŸ’¬ å¿œç­”:")
        print(response)

        # ãƒ­ã‚°ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        save_log(message, response)

    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

def save_log(user_msg, ai_msg):
    from config import MEMORY_DIR
    date_str = datetime.now().strftime("%Y-%m-%d")
    path = MEMORY_DIR / f"{date_str}.json"
    path.parent.mkdir(parents=True, exist_ok=True)

    if path.exists():
        with open(path, "r") as f:
            logs = json.load(f)
    else:
        logs = []

    now = datetime.now(timezone.utc).isoformat()
    logs.append({"timestamp": now, "sender": "user", "message": user_msg})
    logs.append({"timestamp": now, "sender": "ai", "message": ai_msg})

    with open(path, "w") as f:
        json.dump(logs, f, indent=2, ensure_ascii=False)

if __name__ == "__main__":
    main()
