use anyhow::Result;
use async_openai::{
    types::{
        ChatCompletionRequestMessage, 
        CreateChatCompletionRequestArgs, ChatCompletionTool, ChatCompletionToolType,
        FunctionObject, ChatCompletionRequestToolMessage,
        ChatCompletionRequestAssistantMessage, ChatCompletionRequestUserMessage,
        ChatCompletionRequestSystemMessage, ChatCompletionToolChoiceOption
    },
    Client,
};
use serde_json::{json, Value};

use crate::http_client::ServiceClient;

/// OpenAI provider with MCP tools support (matching Python implementation)
pub struct OpenAIProvider {
    client: Client<async_openai::config::OpenAIConfig>,
    model: String,
    service_client: ServiceClient,
    system_prompt: Option<String>,
}

impl OpenAIProvider {
    pub fn new(api_key: String, model: Option<String>) -> Self {
        let config = async_openai::config::OpenAIConfig::new()
            .with_api_key(api_key);
        let client = Client::with_config(config);
        
        Self {
            client,
            model: model.unwrap_or_else(|| "gpt-4".to_string()),
            service_client: ServiceClient::new(),
            system_prompt: None,
        }
    }

    pub fn with_system_prompt(mut self, prompt: String) -> Self {
        self.system_prompt = Some(prompt);
        self
    }

    /// Generate OpenAI tools from MCP endpoints (matching Python implementation)
    fn get_mcp_tools(&self) -> Vec<ChatCompletionTool> {
        let tools = vec![
            // Memory tools
            ChatCompletionTool {
                r#type: ChatCompletionToolType::Function,
                function: FunctionObject {
                    name: "get_memories".to_string(),
                    description: Some("éŽåŽ»ã®ä¼šè©±è¨˜æ†¶ã‚’å–å¾—ã—ã¾ã™ã€‚ã€Œè¦šãˆã¦ã„ã‚‹ã€ã€Œå‰å›žã€ã€Œä»¥å‰ã€ãªã©ã®è³ªå•ã§å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„".to_string()),
                    parameters: Some(json!({
                        "type": "object",
                        "properties": {
                            "limit": {
                                "type": "integer",
                                "description": "å–å¾—ã™ã‚‹è¨˜æ†¶ã®æ•°",
                                "default": 5
                            }
                        }
                    })),
                },
            },
            ChatCompletionTool {
                r#type: ChatCompletionToolType::Function,
                function: FunctionObject {
                    name: "search_memories".to_string(),
                    description: Some("ç‰¹å®šã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦è©±ã—ãŸè¨˜æ†¶ã‚’æ¤œç´¢ã—ã¾ã™ã€‚ã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«ã¤ã„ã¦ã€ã€Œâ—‹â—‹ã«ã¤ã„ã¦è©±ã—ãŸã€ãªã©ã®è³ªå•ã§ä½¿ç”¨ã—ã¦ãã ã•ã„".to_string()),
                    parameters: Some(json!({
                        "type": "object",
                        "properties": {
                            "keywords": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é…åˆ—"
                            }
                        },
                        "required": ["keywords"]
                    })),
                },
            },
            ChatCompletionTool {
                r#type: ChatCompletionToolType::Function,
                function: FunctionObject {
                    name: "get_contextual_memories".to_string(),
                    description: Some("ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹æ–‡è„ˆçš„è¨˜æ†¶ã‚’å–å¾—ã—ã¾ã™".to_string()),
                    parameters: Some(json!({
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "æ¤œç´¢ã‚¯ã‚¨ãƒª"
                            },
                            "limit": {
                                "type": "integer",
                                "description": "å–å¾—ã™ã‚‹è¨˜æ†¶ã®æ•°",
                                "default": 5
                            }
                        },
                        "required": ["query"]
                    })),
                },
            },
            ChatCompletionTool {
                r#type: ChatCompletionToolType::Function,
                function: FunctionObject {
                    name: "get_relationship".to_string(),
                    description: Some("ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®é–¢ä¿‚æ€§æƒ…å ±ã‚’å–å¾—ã—ã¾ã™".to_string()),
                    parameters: Some(json!({
                        "type": "object",
                        "properties": {
                            "user_id": {
                                "type": "string",
                                "description": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"
                            }
                        },
                        "required": ["user_id"]
                    })),
                },
            },
            // ai.card tools
            ChatCompletionTool {
                r#type: ChatCompletionToolType::Function,
                function: FunctionObject {
                    name: "card_get_user_cards".to_string(),
                    description: Some("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰€æœ‰ã™ã‚‹ã‚«ãƒ¼ãƒ‰ã®ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™".to_string()),
                    parameters: Some(json!({
                        "type": "object",
                        "properties": {
                            "did": {
                                "type": "string",
                                "description": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®DID"
                            },
                            "limit": {
                                "type": "integer",
                                "description": "å–å¾—ã™ã‚‹ã‚«ãƒ¼ãƒ‰æ•°ã®ä¸Šé™",
                                "default": 10
                            }
                        },
                        "required": ["did"]
                    })),
                },
            },
            ChatCompletionTool {
                r#type: ChatCompletionToolType::Function,
                function: FunctionObject {
                    name: "card_draw_card".to_string(),
                    description: Some("ã‚¬ãƒãƒ£ã‚’å¼•ã„ã¦ã‚«ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¾ã™".to_string()),
                    parameters: Some(json!({
                        "type": "object",
                        "properties": {
                            "did": {
                                "type": "string",
                                "description": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®DID"
                            },
                            "is_paid": {
                                "type": "boolean",
                                "description": "æœ‰æ–™ã‚¬ãƒãƒ£ã‹ã©ã†ã‹",
                                "default": false
                            }
                        },
                        "required": ["did"]
                    })),
                },
            },
            ChatCompletionTool {
                r#type: ChatCompletionToolType::Function,
                function: FunctionObject {
                    name: "card_analyze_collection".to_string(),
                    description: Some("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚«ãƒ¼ãƒ‰ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ†æžã—ã¾ã™".to_string()),
                    parameters: Some(json!({
                        "type": "object",
                        "properties": {
                            "did": {
                                "type": "string",
                                "description": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®DID"
                            }
                        },
                        "required": ["did"]
                    })),
                },
            },
            ChatCompletionTool {
                r#type: ChatCompletionToolType::Function,
                function: FunctionObject {
                    name: "card_get_gacha_stats".to_string(),
                    description: Some("ã‚¬ãƒãƒ£ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã—ã¾ã™".to_string()),
                    parameters: Some(json!({
                        "type": "object",
                        "properties": {}
                    })),
                },
            },
        ];

        tools
    }

    /// Chat interface with MCP function calling support (matching Python implementation)
    pub async fn chat_with_mcp(&self, prompt: String, user_id: String) -> Result<String> {
        let tools = self.get_mcp_tools();
        
        let system_content = self.system_prompt.as_deref().unwrap_or(
            "ã‚ãªãŸã¯è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã¨é–¢ä¿‚æ€§ãƒ‡ãƒ¼ã‚¿ã€ã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹AIã§ã™ã€‚\n\nã€é‡è¦ã€‘ä»¥ä¸‹ã®å ´åˆã¯å¿…ãšãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼š\n\n1. ã‚«ãƒ¼ãƒ‰é–¢é€£ã®è³ªå•:\n- ã€Œã‚«ãƒ¼ãƒ‰ã€ã€Œã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã€ã€Œã‚¬ãƒãƒ£ã€ã€Œè¦‹ã›ã¦ã€ã€ŒæŒã£ã¦ã„ã‚‹ã€ã€ŒçŠ¶æ³ã€ã€Œã©ã‚“ãªã‚«ãƒ¼ãƒ‰ã€ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆ\n- card_get_user_cardsãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚«ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—\n\n2. è¨˜æ†¶ãƒ»é–¢ä¿‚æ€§ã®è³ªå•:\n- ã€Œè¦šãˆã¦ã„ã‚‹ã€ã€Œå‰å›žã€ã€Œä»¥å‰ã€ã€Œã«ã¤ã„ã¦è©±ã—ãŸã€ã€Œé–¢ä¿‚ã€ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆ\n- é©åˆ‡ãªãƒ¡ãƒ¢ãƒªãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨\n\n3. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š:\n- didãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã¯ç¾åœ¨ä¼šè©±ã—ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®IDï¼ˆä¾‹ï¼š'syui'ï¼‰ã‚’ä½¿ç”¨\n- ãƒ„ãƒ¼ãƒ«ã‚’ç©æ¥µçš„ã«ä½¿ç”¨ã—ã¦æ­£ç¢ºãªæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½•ã‹ã‚’å°‹ã­ãŸæ™‚ã¯ã€ã¾ãšé–¢é€£ã™ã‚‹ãƒ„ãƒ¼ãƒ«ãŒã‚ã‚‹ã‹ã‚’è€ƒãˆã€é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‹ã‚‰å›žç­”ã—ã¦ãã ã•ã„ã€‚"
        );

        let request = CreateChatCompletionRequestArgs::default()
            .model(&self.model)
            .messages(vec![
                ChatCompletionRequestMessage::System(
                    ChatCompletionRequestSystemMessage {
                        content: system_content.to_string().into(),
                        name: None,
                    }
                ),
                ChatCompletionRequestMessage::User(
                    ChatCompletionRequestUserMessage {
                        content: prompt.clone().into(),
                        name: None,
                    }
                ),
            ])
            .tools(tools)
            .tool_choice(ChatCompletionToolChoiceOption::Auto)
            .max_tokens(2000u16)
            .temperature(0.7)
            .build()?;

        let response = self.client.chat().create(request).await?;
        let message = &response.choices[0].message;

        // Handle tool calls
        if let Some(tool_calls) = &message.tool_calls {
            if tool_calls.is_empty() {
                println!("ðŸ”§ [OpenAI] No tools called");
            } else {
                println!("ðŸ”§ [OpenAI] {} tools called:", tool_calls.len());
                for tc in tool_calls {
                    println!("  - {}({})", tc.function.name, tc.function.arguments);
                }
            }
        } else {
            println!("ðŸ”§ [OpenAI] No tools called");
        }

        // Process tool calls if any
        if let Some(tool_calls) = &message.tool_calls {
            if !tool_calls.is_empty() {

            let mut messages = vec![
                ChatCompletionRequestMessage::System(
                    ChatCompletionRequestSystemMessage {
                        content: system_content.to_string().into(),
                        name: None,
                    }
                ),
                ChatCompletionRequestMessage::User(
                    ChatCompletionRequestUserMessage {
                        content: prompt.into(),
                        name: None,
                    }
                ),
                ChatCompletionRequestMessage::Assistant(
                    ChatCompletionRequestAssistantMessage {
                        content: message.content.clone(),
                        name: None,
                        tool_calls: message.tool_calls.clone(),
                        function_call: None,
                    }
                ),
            ];

            // Execute each tool call
            for tool_call in tool_calls {
                println!("ðŸŒ [MCP] Executing {}...", tool_call.function.name);
                let tool_result = self.execute_mcp_tool(tool_call, &user_id).await?;
                let result_preview = serde_json::to_string(&tool_result)?;
                let preview = if result_preview.chars().count() > 100 {
                    format!("{}...", result_preview.chars().take(100).collect::<String>())
                } else {
                    result_preview.clone()
                };
                println!("âœ… [MCP] Result: {}", preview);

                messages.push(ChatCompletionRequestMessage::Tool(
                    ChatCompletionRequestToolMessage {
                        content: serde_json::to_string(&tool_result)?,
                        tool_call_id: tool_call.id.clone(),
                    }
                ));
            }

            // Get final response with tool outputs
            let final_request = CreateChatCompletionRequestArgs::default()
                .model(&self.model)
                .messages(messages)
                .max_tokens(2000u16)
                .temperature(0.7)
                .build()?;

            let final_response = self.client.chat().create(final_request).await?;
                Ok(final_response.choices[0].message.content.as_ref().unwrap_or(&"".to_string()).clone())
            } else {
                // No tools were called
                Ok(message.content.as_ref().unwrap_or(&"".to_string()).clone())
            }
        } else {
            // No tool_calls field at all
            Ok(message.content.as_ref().unwrap_or(&"".to_string()).clone())
        }
    }

    /// Execute MCP tool call (matching Python implementation)
    async fn execute_mcp_tool(&self, tool_call: &async_openai::types::ChatCompletionMessageToolCall, context_user_id: &str) -> Result<Value> {
        let function_name = &tool_call.function.name;
        let arguments: Value = serde_json::from_str(&tool_call.function.arguments)?;

        match function_name.as_str() {
            "get_memories" => {
                let limit = arguments.get("limit").and_then(|v| v.as_i64()).unwrap_or(5);
                // TODO: Implement actual MCP call
                Ok(json!({"info": "è¨˜æ†¶æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™"}))
            }
            "search_memories" => {
                let _keywords = arguments.get("keywords").and_then(|v| v.as_array());
                // TODO: Implement actual MCP call
                Ok(json!({"info": "è¨˜æ†¶æ¤œç´¢æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™"}))
            }
            "get_contextual_memories" => {
                let _query = arguments.get("query").and_then(|v| v.as_str()).unwrap_or("");
                let _limit = arguments.get("limit").and_then(|v| v.as_i64()).unwrap_or(5);
                // TODO: Implement actual MCP call
                Ok(json!({"info": "æ–‡è„ˆè¨˜æ†¶æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™"}))
            }
            "get_relationship" => {
                let _user_id = arguments.get("user_id").and_then(|v| v.as_str()).unwrap_or(context_user_id);
                // TODO: Implement actual MCP call
                Ok(json!({"info": "é–¢ä¿‚æ€§æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™"}))
            }
            // ai.card tools
            "card_get_user_cards" => {
                let did = arguments.get("did").and_then(|v| v.as_str()).unwrap_or(context_user_id);
                let _limit = arguments.get("limit").and_then(|v| v.as_i64()).unwrap_or(10);
                
                match self.service_client.get_user_cards(did).await {
                    Ok(result) => Ok(result),
                    Err(e) => {
                        println!("âŒ ai.card API error: {}", e);
                        Ok(json!({
                            "error": "ai.cardã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“",
                            "message": "ã‚«ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ai.cardã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãã ã•ã„"
                        }))
                    }
                }
            }
            "card_draw_card" => {
                let did = arguments.get("did").and_then(|v| v.as_str()).unwrap_or(context_user_id);
                let is_paid = arguments.get("is_paid").and_then(|v| v.as_bool()).unwrap_or(false);
                
                match self.service_client.draw_card(did, is_paid).await {
                    Ok(result) => Ok(result),
                    Err(e) => {
                        println!("âŒ ai.card API error: {}", e);
                        Ok(json!({
                            "error": "ai.cardã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“",
                            "message": "ã‚«ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ai.cardã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãã ã•ã„"
                        }))
                    }
                }
            }
            "card_analyze_collection" => {
                let did = arguments.get("did").and_then(|v| v.as_str()).unwrap_or(context_user_id);
                // TODO: Implement collection analysis endpoint
                Ok(json!({
                    "info": "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åˆ†æžæ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™",
                    "user_did": did
                }))
            }
            "card_get_gacha_stats" => {
                // TODO: Implement gacha stats endpoint
                Ok(json!({"info": "ã‚¬ãƒãƒ£çµ±è¨ˆæ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™"}))
            }
            _ => {
                Ok(json!({
                    "error": format!("Unknown tool: {}", function_name)
                }))
            }
        }
    }
}